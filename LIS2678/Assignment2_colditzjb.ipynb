{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background:\n",
    "One overarching goal of this research project is to determine the feasibility of using the online Yelp platform to collect business listings for retailers of Electronic Nicotine Delivery Systems (ENDS; e.g., vape shops) in Pennsylvania. To this end, I utilized the Yelp API to collect data for all metropolitan and micropolitan census regions in Pennsylvania (which includes some surrounding states). Each API call was set to maximum search radius of 25 miles, targeting a central zipcode within each identified census region (some geographic overlap was present). \n",
    "\n",
    "Data have been collected from the Yelp API at roughly 1-month intervals from September 2016 through present. Data are currently stored in CSV files. Monthly API calls were repeated using several distinct search terms such as \"vape\", \"vaping\", and \"ecig\" to maximize sensitivity. \n",
    "\n",
    "As a result of overlap in search radii and search terms, each monthly data file contains many redundant listings. As the searches were repeated several times, search results are also redundant among the data files. Also, several results are outside of Pennsylvania, so additional data cleaning is needed to limit the scope of results to Pennsylvania ENDS retailers. \n",
    "\n",
    "Data were collected as part of an ongoing research project at the University of Pittsburgh's [Center for Research on Media, Technology, and Health](http://mth.pitt.edu/) and are stored in [CRMTH's GitHub \"YelpEpi\" repository](https://github.com/CRMTH/YelpEpi/). For the purposes of this project, I forked that repo to [my personal GitHub \"YelpEpi\" repository](https://github.com/colditzjb/YelpEpi/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "First, I needed to clone the repository to my computer. I did this in BASH command line, but I'm including that step for posterity (this may not work as expected within Jupyter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!git clone http://github.com/colditzjb/YelpEpi/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your current working directory (e.g., where you started Jupyter), this repo may end up in a different location on your own computer. Change this next line to point to the correct directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_in = '//home/jason/repos/YelpEpi/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now that we're (hopefully) on the same page, let's navigate to the data subdirectory and see what we're working with..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016-09-02.csv',\n",
       " '2016-09-30.csv',\n",
       " '2016-10-31.csv',\n",
       " '2016-11-30.csv',\n",
       " '2017-01-03.csv',\n",
       " '2017-01-31.csv',\n",
       " '2017-02-28.csv',\n",
       " '2017-04-03.csv',\n",
       " '2017-05-01.csv',\n",
       " '2017-05-30.csv',\n",
       " 'README.md']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data_dir = dir_in+'data/'\n",
    "files = sorted(os.listdir(data_dir)) # Use sorted() to list them in ascending order\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple issues:\n",
    "* There is a README.md file among the CSV data files, so we'll need to ignore that.\n",
    "* The data collection dates are in the file names, and we'll need those for later.\n",
    "\n",
    "Let's clean that up a bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extension is:\t.csv\n",
      "filename is:\t2017-05-01\n"
     ]
    }
   ],
   "source": [
    "# Figuring out the slicing options\n",
    "f = '2017-05-01.csv'\n",
    "print('extension is:\\t'+f[-4:]) # Use this to select only CSV files\n",
    "print('filename is:\\t'+f[:-4]) # Use this for parsing out dates, later on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016-09-02.csv',\n",
       " '2016-09-30.csv',\n",
       " '2016-10-31.csv',\n",
       " '2016-11-30.csv',\n",
       " '2017-01-03.csv',\n",
       " '2017-01-31.csv',\n",
       " '2017-02-28.csv',\n",
       " '2017-04-03.csv',\n",
       " '2017-05-01.csv',\n",
       " '2017-05-30.csv']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making lists of only CSV files\n",
    "files_csv = []\n",
    "for f in files:\n",
    "    if '.csv' in f[-4:]:\n",
    "        files_csv.append(f)\n",
    "files = files_csv \n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll read in the first CSV file as a Pandas object and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>termnum</th>\n",
       "      <th>term</th>\n",
       "      <th>category</th>\n",
       "      <th>radius_miles</th>\n",
       "      <th>loci</th>\n",
       "      <th>location</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>distance</th>\n",
       "      <th>i</th>\n",
       "      <th>...</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_count</th>\n",
       "      <th>name</th>\n",
       "      <th>phone</th>\n",
       "      <th>display_address</th>\n",
       "      <th>url</th>\n",
       "      <th>yelpcats</th>\n",
       "      <th>isWTS</th>\n",
       "      <th>isTobShop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>vape</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>Allentown-Bethlehem-Easton | PA-NJ Metro Area ...</td>\n",
       "      <td>40.549806</td>\n",
       "      <td>-75.491105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Get Your Vape On</td>\n",
       "      <td>6104218310</td>\n",
       "      <td>610 State Ave | Emmaus PA 18049</td>\n",
       "      <td>http://www.yelp.com/biz/get-your-vape-on-emmau...</td>\n",
       "      <td>vapeshops |</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>vape</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>Allentown-Bethlehem-Easton | PA-NJ Metro Area ...</td>\n",
       "      <td>40.549495</td>\n",
       "      <td>-75.597692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2</td>\n",
       "      <td>Vape Flow</td>\n",
       "      <td>4846498347</td>\n",
       "      <td>7150 Hamilton Blvd | Trexlertown PA 18087</td>\n",
       "      <td>http://www.yelp.com/biz/vape-flow-trexlertown-...</td>\n",
       "      <td>vapeshops |</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>vape</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>Allentown-Bethlehem-Easton | PA-NJ Metro Area ...</td>\n",
       "      <td>40.629023</td>\n",
       "      <td>-75.477516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Blue Monkey Vape</td>\n",
       "      <td>6102310555</td>\n",
       "      <td>250 Lehigh Valley Mall | Whitehall PA 18052</td>\n",
       "      <td>http://www.yelp.com/biz/blue-monkey-vape-white...</td>\n",
       "      <td>vapeshops |</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   termnum  term  category  radius_miles  loci  \\\n",
       "0        0  vape       NaN            25     1   \n",
       "1        0  vape       NaN            25     1   \n",
       "2        0  vape       NaN            25     1   \n",
       "\n",
       "                                            location        lat        lng  \\\n",
       "0  Allentown-Bethlehem-Easton | PA-NJ Metro Area ...  40.549806 -75.491105   \n",
       "1  Allentown-Bethlehem-Easton | PA-NJ Metro Area ...  40.549495 -75.597692   \n",
       "2  Allentown-Bethlehem-Easton | PA-NJ Metro Area ...  40.629023 -75.477516   \n",
       "\n",
       "   distance  i    ...     is_closed rating  review_count              name  \\\n",
       "0       NaN  1    ...         False    4.0             4  Get Your Vape On   \n",
       "1       NaN  2    ...         False    4.5             2         Vape Flow   \n",
       "2       NaN  3    ...         False    1.0             1  Blue Monkey Vape   \n",
       "\n",
       "        phone                              display_address  \\\n",
       "0  6104218310              610 State Ave | Emmaus PA 18049   \n",
       "1  4846498347    7150 Hamilton Blvd | Trexlertown PA 18087   \n",
       "2  6102310555  250 Lehigh Valley Mall | Whitehall PA 18052   \n",
       "\n",
       "                                                 url      yelpcats isWTS  \\\n",
       "0  http://www.yelp.com/biz/get-your-vape-on-emmau...  vapeshops |    NaN   \n",
       "1  http://www.yelp.com/biz/vape-flow-trexlertown-...  vapeshops |    NaN   \n",
       "2  http://www.yelp.com/biz/blue-monkey-vape-white...  vapeshops |    NaN   \n",
       "\n",
       "   isTobShop  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(data_dir+files[0])\n",
    "df.head(3) # Only display the first 3 records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's confirm that all of the files are Pandas-readable...\n",
    "\n",
    "_Spoiler alert:_ they're not all good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-09-02.csv is all good\n",
      "2016-09-30.csv is all good\n",
      "2016-10-31.csv is all good\n",
      "2016-11-30.csv is all good\n",
      "2017-01-03.csv is NOT good\n",
      "2017-01-31.csv is NOT good\n",
      "2017-02-28.csv is NOT good\n",
      "2017-04-03.csv is NOT good\n",
      "2017-05-01.csv is all good\n",
      "2017-05-30.csv is all good\n"
     ]
    }
   ],
   "source": [
    "for f in files:\n",
    "    try:\n",
    "        df = pd.read_csv(data_dir+f)\n",
    "        print(f+' is all good')\n",
    "    except:\n",
    "        print(f+' is NOT good')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going on with the \"NOT good\" files?!\n",
    "\n",
    "Let's iterate to find the error..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 2336: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-79e1beb40896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'2017-01-03.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 2336: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "for line in open(data_dir+'2017-01-03.csv'):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the file in question..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last good line was #944 and had this data:\n",
      "\n",
      "0,vape,,25,36,York-Hanover | PA Metro Area; Pennsylvania (Spring Grove | PA),39.9766769,-76.7686615,5516.60113329,18,djs-westgate-beverage-york,False,4.0,1,DJ's Westgate Beverage,7177641550,1550 Kenneth Rd | York PA 17408,https://www.yelp.com/biz/djs-westgate-beverage-york?adjust_creative=wDwCvDADIHyvJYDHOmNK2g&utm_campaign=yelp_api&utm_medium=api_v2_search&utm_source=wDwCvDADIHyvJYDHOmNK2g,beer_and_wine | tobaccoshops | \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lineNum = 0\n",
    "try:\n",
    "    for line in open(data_dir+'2017-01-03.csv'):\n",
    "        lineNum += 1\n",
    "        pass\n",
    "except:\n",
    "    print('Last good line was #'+str(lineNum)+' and had this data:\\n')\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we know that there is a utf-8 encoding error around line # 944 in the '2017-01-03.csv' file (and also in some subsequent files). Upon reviewing the raw data, there weren't any obviously strange text characters, so we're going to try a different encoding strategy.\n",
    "\n",
    "After some trial-and-error (and various StackOverflow pages), _\"latin-1\"_ might be a viable encoding strategy when interpreting text from an API that is international in scope. Let's try that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-09-02.csv is all good\n",
      "2016-09-30.csv is all good\n",
      "2016-10-31.csv is all good\n",
      "2016-11-30.csv is all good\n",
      "2017-01-03.csv is all good\n",
      "2017-01-31.csv is all good\n",
      "2017-02-28.csv is all good\n",
      "2017-04-03.csv is all good\n",
      "2017-05-01.csv is all good\n",
      "2017-05-30.csv is all good\n"
     ]
    }
   ],
   "source": [
    "for f in files:\n",
    "    try:\n",
    "        df = pd.read_csv(data_dir+f, encoding='latin-1')\n",
    "        print(f+' is all good')\n",
    "    except:\n",
    "        print(f+' is NOT good')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Success - it's all good!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the repository...\n",
    "\n",
    "Note on how I \"save\" my work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git config user.email \"colditzjb@gmail.com\"\n",
    "#!git commit -m \"update files\"\n",
    "#!git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documenting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read these CSV files into four Pandas Dataframes\n",
    "    * Read the `id` column in as an index (using the `index_col` parameter of the `read_csv` function). See the [column and index locations documentation](http://pandas.pydata.org/pandas-docs/stable/io.html#column-and-index-locations-and-names) for more information.\n",
    "    * Parse any date columns (using the `parse_date` and `infer_datetime_format` parameters of the `read_csv` function). See the [datetime-handling documentation](http://pandas.pydata.org/pandas-docs/stable/io.html#datetime-handling) for more information.\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
